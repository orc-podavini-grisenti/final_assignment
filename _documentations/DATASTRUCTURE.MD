# ðŸ“‚â€‹ Directory Structure:
```graphql
final_assignemnt/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ _documentations/    
â”‚   â”œâ”€â”€ DATASTRUCTURE.md
â”‚   â”œâ”€â”€ navigation_videos/ 
â”‚   â””â”€â”€ tracking_video/     
â”‚
â”œâ”€â”€ configs/        # Enviroment Configuration Files:
â”‚   â”œâ”€â”€ env.yaml            # randome environment with 3 obstacle
â”‚   â”œâ”€â”€ empty_env.yaml      # enviroment without obstacle and random goal   
â”‚   â”œâ”€â”€ fixed_env.yaml      # fixed enviroment    
â”‚   â””â”€â”€ env_nav_ev.yaml     # randome environment with 10 obstacle
â”‚
â”œâ”€â”€ controllers/    # Implementation of classic and RL:
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ lyapunov_controller.py
â”‚   â””â”€â”€ rl_controller.py    # wrapper that call the policy
â”‚
â”œâ”€â”€ envs/           # Defines the RL environment:
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ obstacles.py        # obstacle handling
|   â”œâ”€â”€ test_env.py         # test environment script
|   â”œâ”€â”€ unicycle_env.py     # global environment definition
â”‚   â”œâ”€â”€ rewards.py          # reward function
â”‚   â””â”€â”€ README.md          
â”‚
â”œâ”€â”€ evaluation/      # Contain the evaluation scripts:
â”‚   â”œâ”€â”€ output/             # store all the evaluation results and outputs
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ controller_evaluation.py        
|   â”œâ”€â”€ navigation_evaluation.py         
|   â”œâ”€â”€ README.md           # explain how to run all the evaluation process
â”‚   â”œâ”€â”€ statistics,py       # implement statistical analysis methods 
â”‚   â””â”€â”€ utils.py            
â”‚
â”œâ”€â”€ models/         # Neural networks only:
â”‚   â”œâ”€â”€ trajectory_tracking_network.py      
â”‚   â”œâ”€â”€ value_network.py                # network used to estimate the value function 
â”‚   â””â”€â”€ navigation_network.py           # Actor and Critic networks for PPO
â”‚ 
â”œâ”€â”€ planner/         # Dubins Planner:
â”‚   â”œâ”€â”€ __init__.py    
â”‚   â”œâ”€â”€ dubins_planner.py        # Implementation of the Dubins Planner class
â”‚   â””â”€â”€ dubins_test.py           # simple dubins planner testing
â”‚
â”œâ”€â”€ scripts/        # Launch Scripts
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ run_nav_evaluation.py       # launch script for all the navigation evaluation    
â”‚   â”œâ”€â”€ run_navigation.py           # launch script for a navigation episode              
â”‚   â”œâ”€â”€ run_tracking_evaluation.py  # launch script for all the tracking evaluation    
â”‚   â””â”€â”€ run_trajectory_tracking.py   # launch script fro a tracking episode
â”‚
â”œâ”€â”€ training/      # Scripts to train the policy and evaluate it
â”‚   â”œâ”€â”€ experimets/             # locla storage for trainign ( gitignore )
â”‚   â”‚   â””â”€â”€ ... 
â”‚   â”œâ”€â”€ nav_1/                  # contain the navigation policy
â”‚   â”‚   â””â”€â”€ ... 
â”‚   â”œâ”€â”€ v1_no_baseline/         # contain the tracking policy trained without baseline
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ v2_baseline/            # contain the tracking policy trained with baseline
â”‚   â”‚   â””â”€â”€ ... 
â”‚   â”œâ”€â”€ navigation.ipynb                # training noteboock for PPO navigation policy 
â”‚   â”œâ”€â”€ reinforcment_baseline.ipynb     # training noteboock for Reinfocment with baseline 
â”‚   â””â”€â”€ reinforcment.ipynb              # training noteboock for Reinfocment without baseline
â”‚ 
â”œâ”€â”€ utils/
    â”œâ”€â”€ normalization.py    # normalize the input of the networks
    â”œâ”€â”€ simulation.py       # run a single simulation on the enviroment
    â””â”€â”€ reward.py           # reward functions implementation

```